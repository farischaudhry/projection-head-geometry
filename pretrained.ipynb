{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f417205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import entropy, sem\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "\n",
    "def exclude_bias_and_norm(name):\n",
    "    \"\"\"Dummy function to fix projection head initialization.\"\"\"\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bffc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# DINO (ViT and ResNet)\n",
    "# =================================\n",
    "class DINOHead_ViT(nn.Module):\n",
    "    \"\"\"ViT Head: Uses Weight Norm\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, bottleneck_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, bottleneck_dim),\n",
    "        )\n",
    "        self.last_layer = nn.utils.weight_norm(nn.Linear(bottleneck_dim, out_dim, bias=False))\n",
    "        self.last_layer.weight_g.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = nn.functional.normalize(x, dim=-1, p=2)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DINOHead_ResNet(nn.Module):\n",
    "    \"\"\"ResNet Head: Uses BatchNorm\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, bottleneck_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),       \n",
    "            nn.BatchNorm1d(hidden_dim),          \n",
    "            nn.GELU(),                           \n",
    "            nn.Linear(hidden_dim, bottleneck_dim)\n",
    "        )\n",
    "        self.last_layer = nn.Linear(bottleneck_dim, out_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = nn.functional.normalize(x, dim=-1, p=2)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DINO_Local(nn.Module):\n",
    "    def __init__(self, arch, ckpt_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load Backbone\n",
    "        if arch == 'resnet50':\n",
    "            self.backbone = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\n",
    "        elif arch == 'vit_s':\n",
    "            self.backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "            \n",
    "        # Inspect Checkpoint\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            raise FileNotFoundError(f\"Missing: {ckpt_path}\")\n",
    "            \n",
    "        print(f\"Inspecting {ckpt_path}...\")\n",
    "        \n",
    "        def exclude_fns(name): return False\n",
    "        with torch.serialization.safe_globals({\"exclude_bias_and_norm\": exclude_fns}):\n",
    "            full_checkpoint = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "            \n",
    "        state = full_checkpoint['teacher'] if 'teacher' in full_checkpoint else full_checkpoint\n",
    "        \n",
    "        # Auto-Detect Dimensions \n",
    "        # Find MLP Input/Hidden dims\n",
    "        mlp_key = next(k for k in state.keys() if \"head.mlp.0.weight\" in k)\n",
    "        in_dim = state[mlp_key].shape[1]      \n",
    "        hidden_dim = state[mlp_key].shape[0]  \n",
    "        \n",
    "        # Find Output/Bottleneck dims\n",
    "        if any(\"head.last_layer.weight_v\" in k for k in state.keys()):\n",
    "            last_key = next(k for k in state.keys() if \"head.last_layer.weight_v\" in k)\n",
    "            has_wn = True\n",
    "        else:\n",
    "            last_key = next(k for k in state.keys() if \"head.last_layer.weight\" in k)\n",
    "            has_wn = False\n",
    "            \n",
    "        # Shape is [Output, Input] -> [out_dim, bottleneck_dim]\n",
    "        bottleneck_dim = state[last_key].shape[1] \n",
    "        out_dim = state[last_key].shape[0]        \n",
    "        \n",
    "        print(f\" -> Detected: In={in_dim}, Hidden={hidden_dim}, Bottle={bottleneck_dim}, Out={out_dim}\")\n",
    "\n",
    "        # Init Head\n",
    "        if has_wn:\n",
    "            print(\" -> Type: ViT Head (WeightNorm)\")\n",
    "            self.head = DINOHead_ViT(in_dim, out_dim, hidden_dim, bottleneck_dim)\n",
    "        else:\n",
    "            print(\" -> Type: ResNet Head (BatchNorm)\")\n",
    "            self.head = DINOHead_ResNet(in_dim, out_dim, hidden_dim, bottleneck_dim)\n",
    "\n",
    "        # Clean & Load\n",
    "        clean_state = {}\n",
    "        for k, v in state.items():\n",
    "            k = k.replace(\"teacher.\", \"\")\n",
    "            clean_state[k] = v\n",
    "            \n",
    "        self.load_state_dict(clean_state, strict=True)\n",
    "        print(f\" -> Load Status: Success\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        if \"ViT\" in str(type(self.backbone)):\n",
    "            z = self.backbone(x)\n",
    "        else:\n",
    "            z = self.backbone(x)\n",
    "            if len(z.shape) == 4: z = torch.flatten(z, 1)\n",
    "        return z, self.head(z)\n",
    "\n",
    "\n",
    "# =================================\n",
    "# VICReg (ResNet)\n",
    "# =================================\n",
    "class VICReg_Local(nn.Module):\n",
    "    def __init__(self, ckpt_path):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.resnet50()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(2048, 8192), nn.BatchNorm1d(8192), nn.ReLU(True),\n",
    "            nn.Linear(8192, 8192), nn.BatchNorm1d(8192), nn.ReLU(True),\n",
    "            nn.Linear(8192, 8192, bias=False) \n",
    "        )\n",
    "        print(f\"Loading {ckpt_path}...\")\n",
    "        def exclude_fns(name): return False\n",
    "        with torch.serialization.safe_globals({\"exclude_bias_and_norm\": exclude_fns}):\n",
    "            ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "        state_dict = ckpt['model'] if 'model' in ckpt else ckpt\n",
    "        backbone_state = {k.replace('module.backbone.', ''): v for k, v in state_dict.items() if 'module.backbone.' in k}\n",
    "        projector_state = {k.replace('module.projector.', ''): v for k, v in state_dict.items() if 'module.projector.' in k}\n",
    "        self.backbone.load_state_dict(backbone_state)\n",
    "        self.projector.load_state_dict(projector_state)\n",
    "        print(\" -> Load Status: Success\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        z = torch.flatten(z, 1)\n",
    "        h = self.projector(z)\n",
    "        return z, h\n",
    "    \n",
    "    \n",
    "# =================================\n",
    "# Barlow Twins (ResNet)\n",
    "# =================================\n",
    "class BarlowTwins_Local(nn.Module):\n",
    "    def __init__(self, ckpt_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone (ResNet50)\n",
    "        self.backbone = torchvision.models.resnet50()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Projector (3 Layers: 8192 -> 8192 -> 8192)\n",
    "        sizes = [2048, 8192, 8192, 8192]\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=False))\n",
    "            layers.append(nn.BatchNorm1d(sizes[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1], bias=False))\n",
    "        self.projector = nn.Sequential(*layers)\n",
    "        \n",
    "        # Load Weights\n",
    "        print(f\"Loading {ckpt_path}...\")\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            raise FileNotFoundError(f\"Missing: {ckpt_path}\")\n",
    "\n",
    "        def exclude_fns(name): return False\n",
    "        with torch.serialization.safe_globals({\"exclude_bias_and_norm\": exclude_fns}):\n",
    "            ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "        # Handle 'model' key if present (standard in Barlow checkpoints)\n",
    "        state_dict = ckpt['model'] if 'model' in ckpt else ckpt\n",
    "        \n",
    "        # Clean keys (Remove 'module.')\n",
    "        clean_state = {}\n",
    "        for k, v in state_dict.items():\n",
    "            k = k.replace(\"module.\", \"\")\n",
    "            clean_state[k] = v\n",
    "            \n",
    "        # Separate into backbone and projector\n",
    "        # Official keys are usually 'backbone.xxx' and 'projector.xxx'\n",
    "        backbone_keys = {k.replace(\"backbone.\", \"\"): v for k, v in clean_state.items() if \"backbone.\" in k}\n",
    "        projector_keys = {k.replace(\"projector.\", \"\"): v for k, v in clean_state.items() if \"projector.\" in k}\n",
    "        \n",
    "        msg_b = self.backbone.load_state_dict(backbone_keys, strict=False)\n",
    "        msg_p = self.projector.load_state_dict(projector_keys, strict=True)\n",
    "        print(f\" -> Load Status: Backbone={msg_b}, Projector={msg_p}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        h = self.projector(z)\n",
    "        return z, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c034052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume the checkpoint files are in the 'pretrained/' directory \n",
    "# and have been renamed to the following filenames.\n",
    "checkpoints = {\n",
    "    \"DINO ViT-S\": {\n",
    "        \"type\": \"dino\",\n",
    "        \"arch\": \"vit_s\",\n",
    "        \"path\": \"pretrained/dino_deitsmall16_fullckpt.pth\"\n",
    "    },\n",
    "    \"DINO ResNet50\": {\n",
    "        \"type\": \"dino\",\n",
    "        \"arch\": \"resnet50\",\n",
    "        \"path\": \"pretrained/dino_resnet50_fullckpt.pth\" \n",
    "    },\n",
    "    \"VICReg ResNet50\": {\n",
    "        \"type\": \"vicreg\",\n",
    "        \"arch\": \"resnet50\",\n",
    "        \"path\": \"pretrained/vicreg_resnet50_fullckpt.pth\"\n",
    "    },\n",
    "    \"Barlow Twins ResNet50\": {\n",
    "        \"type\": \"barlow\",\n",
    "        \"arch\": \"resnet50\",\n",
    "        \"path\": \"pretrained/barlowtwins_resnet50_fullckpt.pth\" \n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"{'Model':<25} | {'Status':<30}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "loaded_models = {} \n",
    "\n",
    "for name, cfg in checkpoints.items():\n",
    "    if not os.path.exists(cfg['path']):\n",
    "        print(f\"{name:<25} | File Not Found\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # Instantiate\n",
    "        if cfg['type'] == 'dino':\n",
    "            model = DINO_Local(cfg['arch'], cfg['path'])\n",
    "        elif cfg['type'] == 'vicreg':\n",
    "            model = VICReg_Local(cfg['path'])\n",
    "        elif cfg['type'] == 'barlow':\n",
    "            model = BarlowTwins_Local(cfg['path'])\n",
    "            \n",
    "        model.cuda().eval()\n",
    "        \n",
    "        # Test\n",
    "        z, h = model(torch.randn(2, 3, 224, 224).cuda())\n",
    "        print(f\"{name:<25} | Ready (z={z.shape[1]}, h={h.shape[1]})\")\n",
    "        # Save\n",
    "        loaded_models[name] = model \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{name:<25} | Error: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86ddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Summary Table (Seed=0)\n",
      "================================================================================================================================================================\n",
      "Model                  | Orbit      || DIMENSIONALITY (Rank) || VARIANCE            | COLLAPSE                 || CURVATURE                    || ALIGNMENT                  \n",
      "                       |            || Backbone  Head      || Backbone  Head      | Ratio (95% CI)           || Backbone  Head      Ratio    || Cos(B)    Cos(H)    Gain    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--- DINO ViT-S ---\n",
      "DINO ViT-S             | rotation   || 3.648814  2.722318  || 5.121819  0.004150  | 1284.3635±61.9525        || 39.095955 13.976097 0.3581   || 0.418339  0.756372  +0.338033\n",
      "DINO ViT-S             | hue        || 6.496621  3.072013  || 2.247406  0.001261  | 2498.6184±321.2806       || 43.918747 12.802624 0.2903   || 0.681305  0.911384  +0.230080\n",
      "DINO ViT-S             | saturation || 2.454316  2.363897  || 2.001809  0.000882  | 2898.0669±435.6995       || 11.260080 3.469745  0.3052   || 0.613487  0.935525  +0.322038\n",
      "DINO ViT-S             | blur       || 2.009811  1.731986  || 0.905378  0.000457  | 3727.7266±857.9131       || 4.649845  1.421318  0.2980   || 0.945867  0.988877  +0.043010\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--- DINO ResNet50 ---\n",
      "DINO ResNet50          | rotation   || 4.347889  2.392087  || 0.003480  0.000027  | 176.1757±26.0717         || 2.760441  1.263809  0.4546   || 0.585585  0.999974  +0.414390\n",
      "DINO ResNet50          | hue        || 6.719608  3.702875  || 0.001300  0.000008  | 223.0947±31.5810         || 2.713123  1.064586  0.4052   || 0.747188  0.999981  +0.252793\n",
      "DINO ResNet50          | saturation || 2.601030  2.198146  || 0.000773  0.000011  | 116.9248±22.3301         || 0.680876  0.402313  0.6072   || 0.688085  0.999969  +0.311884\n",
      "DINO ResNet50          | blur       || 1.860613  1.663187  || 0.001730  0.000010  | 227.1958±29.3320         || 0.600973  0.241705  0.4073   || 0.886287  0.999986  +0.113698\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--- VICReg ResNet50 ---\n",
      "VICReg ResNet50        | rotation   || 3.822999  3.321873  || 0.047115  0.046038  | 1.4256±0.2081            || 8.512438  18.282316 2.1477   || 0.501653  0.134085  -0.367568\n",
      "VICReg ResNet50        | hue        || 6.705080  4.500914  || 0.022224  0.016649  | 2.1492±0.4565            || 11.733534 19.368706 1.6563   || 0.668593  0.267688  -0.400905\n",
      "VICReg ResNet50        | saturation || 2.557318  2.182199  || 0.013407  0.017307  | 1.1331±0.1874            || 2.679302  6.132445  2.3053   || 0.606358  0.236394  -0.369963\n",
      "VICReg ResNet50        | blur       || 1.786645  1.752431  || 0.008369  0.015362  | 0.8514±0.1631            || 1.096246  3.190173  2.8773   || 0.959668  0.917261  -0.042407\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--- Barlow Twins ResNet50 ---\n",
      "Barlow Twins ResNet50  | rotation   || 3.816125  3.480146  || 0.003478  0.001796  | 2.6268±0.3414            || 2.198785  4.029040  1.8290   || 0.481395  0.124903  -0.356493\n",
      "Barlow Twins ResNet50  | hue        || 7.060817  4.422062  || 0.001359  0.000718  | 2.5214±0.3207            || 2.979187  4.392895  1.4920   || 0.655792  0.266119  -0.389673\n",
      "Barlow Twins ResNet50  | saturation || 2.748652  2.625995  || 0.000948  0.000661  | 2.4919±0.6900            || 0.789553  1.492646  1.9027   || 0.599298  0.265185  -0.334113\n",
      "Barlow Twins ResNet50  | blur       || 1.819236  1.723901  || 0.000558  0.000712  | 1.4193±0.3304            || 0.310128  0.696435  2.2432   || 0.959697  0.911310  -0.048387\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Configuration & Reproducibility\n",
    "# ============================================================================\n",
    "@dataclass\n",
    "class AnalysisConfig:\n",
    "    batch_size: int = 64\n",
    "    num_samples_orbit: int = 50   \n",
    "    steps: int = 12               \n",
    "    seed: int = 0\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "config = AnalysisConfig()\n",
    "set_seed(config.seed)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Data Loading (CIFAR-10)\n",
    "# ============================================================================\n",
    "transform = T.Compose([\n",
    "    T.Resize(224), T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Geometric Metrics\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_effective_rank(traj):\n",
    "    \"\"\"Computes Effective Rank via Shannon Entropy of Singular Values.\"\"\"\n",
    "    traj = traj - np.mean(traj, axis=0)\n",
    "    _, S, _ = np.linalg.svd(traj, full_matrices=False)\n",
    "    eig_vals = S**2\n",
    "    total_energy = np.sum(eig_vals) + 1e-10\n",
    "    probs = eig_vals / total_energy\n",
    "    ent = entropy(probs)\n",
    "    return np.exp(ent)\n",
    "\n",
    "def calculate_curvature(traj):\n",
    "    \"\"\"\n",
    "    Computes Local Curvature using Central Finite Differences.\n",
    "    Formula: k_t = || z_{t+1} - 2z_t + z_{t-1} ||\n",
    "    \"\"\"\n",
    "    curvatures = []\n",
    "    \n",
    "    # Iterate from t=1 to T-1 (skipping endpoints)\n",
    "    for t in range(1, len(traj) - 1):\n",
    "        z_prev = traj[t-1]\n",
    "        z_curr = traj[t]\n",
    "        z_next = traj[t+1]\n",
    "        \n",
    "        # Central Second Derivative (Acceleration Vector)\n",
    "        acc_vec = z_next - 2*z_curr + z_prev\n",
    "        \n",
    "        # Curvature = Magnitude (Norm) of this vector\n",
    "        k = np.linalg.norm(acc_vec)\n",
    "        curvatures.append(k)\n",
    "        \n",
    "    return np.mean(curvatures)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main Analysis Loop\n",
    "# ============================================================================\n",
    "\n",
    "def get_orbit_generator(orbit_type, steps):\n",
    "    if orbit_type == 'rotation':\n",
    "        values = np.linspace(0, 45, steps)\n",
    "        func = lambda img, v: TF.rotate(img.unsqueeze(0), float(v))\n",
    "    elif orbit_type == 'hue':\n",
    "        values = np.linspace(-0.4, 0.4, steps)\n",
    "        func = lambda img, v: TF.adjust_hue(img.unsqueeze(0), float(v))\n",
    "    elif orbit_type == 'saturation':\n",
    "        values = np.linspace(0.0, 2.0, steps)\n",
    "        func = lambda img, v: TF.adjust_saturation(img.unsqueeze(0), float(v))\n",
    "    elif orbit_type == 'blur':\n",
    "        values = np.linspace(0.1, 3.0, steps)\n",
    "        func = lambda img, v: T.GaussianBlur(kernel_size=23, sigma=float(v))(img.unsqueeze(0))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown orbit: {orbit_type}\")\n",
    "    return values, func\n",
    "\n",
    "\n",
    "def analyze_full_spectrum(model, dataloader, config, orbit_type):\n",
    "    model.eval()\n",
    "    values, transform_func = get_orbit_generator(orbit_type, config.steps)\n",
    "    \n",
    "    stats = {\n",
    "        'var_backbone': [], 'var_head': [], 'ratio_collapse': [],\n",
    "        'rank_backbone': [], 'rank_head': [],\n",
    "        'curv_backbone': [], 'curv_head': [], 'ratio_curv': [],\n",
    "        'cos_backbone': [], 'cos_head': [], 'gain': []\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(dataloader):\n",
    "            if i * config.batch_size >= config.num_samples_orbit: break\n",
    "            images = images.cuda()\n",
    "            \n",
    "            for img in images:\n",
    "                # Anchors\n",
    "                anchor_b, anchor_h = model(img.unsqueeze(0))\n",
    "                anchor_b = F.normalize(anchor_b.flatten(1), dim=1)\n",
    "                anchor_h = F.normalize(anchor_h.flatten(1), dim=1)\n",
    "                \n",
    "                # Trajectories\n",
    "                traj_b_raw, traj_h_raw = [], []\n",
    "                traj_cos_b, traj_cos_h = [], []\n",
    "                \n",
    "                for val in values:\n",
    "                    aug = transform_func(img, val)\n",
    "                    backbone, head = model(aug)\n",
    "                    \n",
    "                    # Raw\n",
    "                    traj_b_raw.append(backbone.cpu().numpy().flatten())\n",
    "                    traj_h_raw.append(head.cpu().numpy().flatten())\n",
    "                    \n",
    "                    # Cosine\n",
    "                    b_n = F.normalize(backbone.flatten(1), dim=1)\n",
    "                    h_n = F.normalize(head.flatten(1), dim=1)\n",
    "                    traj_cos_b.append(torch.mm(anchor_b, b_n.T).item())\n",
    "                    traj_cos_h.append(torch.mm(anchor_h, h_n.T).item())\n",
    "\n",
    "                # Compute metrics\n",
    "                tb, th = np.stack(traj_b_raw), np.stack(traj_h_raw)\n",
    "                \n",
    "                # Variance\n",
    "                vb = np.mean(np.var(tb, axis=0))\n",
    "                vh = np.mean(np.var(th, axis=0))\n",
    "                \n",
    "                # Rank\n",
    "                rb = calculate_effective_rank(tb)\n",
    "                rh = calculate_effective_rank(th)\n",
    "                \n",
    "                # Curvature\n",
    "                cb = calculate_curvature(tb)\n",
    "                ch = calculate_curvature(th)\n",
    "                \n",
    "                # Alignment\n",
    "                mb, mh = np.mean(traj_cos_b), np.mean(traj_cos_h)\n",
    "                \n",
    "                # Store\n",
    "                stats['var_backbone'].append(vb)\n",
    "                stats['var_head'].append(vh)\n",
    "                stats['ratio_collapse'].append(vb / (vh + 1e-12))\n",
    "                \n",
    "                stats['rank_backbone'].append(rb)\n",
    "                stats['rank_head'].append(rh)\n",
    "                \n",
    "                stats['curv_backbone'].append(cb)\n",
    "                stats['curv_head'].append(ch)\n",
    "                stats['ratio_curv'].append(ch / (cb + 1e-12))\n",
    "                \n",
    "                stats['cos_backbone'].append(mb)\n",
    "                stats['cos_head'].append(mh)\n",
    "                stats['gain'].append(mh - mb)\n",
    "\n",
    "    # Aggregate\n",
    "    results = {k: np.mean(v) for k, v in stats.items()}\n",
    "    results['sem_ratio_collapse'] = sem(stats['ratio_collapse'])\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Execution \n",
    "# ============================================================================\n",
    "\n",
    "print(f\"{'='*160}\")\n",
    "print(f\"Summary Table (Seed={config.seed})\")\n",
    "print(f\"{'='*160}\")\n",
    "\n",
    "print(f\"{'Model':<22} | {'Orbit':<10} || {'DIMENSIONALITY (Rank)':<19} || {'VARIANCE':<19} | {'COLLAPSE':<24} || {'CURVATURE':<28} || {'ALIGNMENT':<27}\")\n",
    "print(f\"{'':<22} | {'':<10} || {'Backbone':<9} {'Head':<9} || {'Backbone':<9} {'Head':<9} | {'Ratio (95% CI)':<24} || {'Backbone':<9} {'Head':<9} {'Ratio':<8} || {'Cos(B)':<9} {'Cos(H)':<9} {'Gain':<8}\")\n",
    "print(\"-\" * 160)\n",
    "\n",
    "orbit_types = ['rotation', 'hue', 'saturation', 'blur']\n",
    "\n",
    "if 'loaded_models' not in locals():\n",
    "    print(\"Error: Run model loading first\")\n",
    "else:\n",
    "    for model_name, model in loaded_models.items():\n",
    "        print(f\"--- {model_name} ---\")\n",
    "        for orbit in orbit_types:\n",
    "            try:\n",
    "                res = analyze_full_spectrum(model, loader, config, orbit)\n",
    "                \n",
    "                ci = res['sem_ratio_collapse'] * 1.96\n",
    "                coll_str = f\"{res['ratio_collapse']:.4f}±{ci:.4f}\"\n",
    "                \n",
    "                print(f\"{model_name:<22} | {orbit:<10} || \"\n",
    "                      f\"{res['rank_backbone']:<9.6f} {res['rank_head']:<9.6f} || \"\n",
    "                      f\"{res['var_backbone']:<9.6f} {res['var_head']:<9.6f} | \"\n",
    "                      f\"{coll_str:<24} || \"\n",
    "                      f\"{res['curv_backbone']:<9.6f} {res['curv_head']:<9.6f} {res['ratio_curv']:<8.4f} || \"\n",
    "                      f\"{res['cos_backbone']:<9.6f} {res['cos_head']:<9.6f} {res['gain']:<+8.6f}\")\n",
    "                      \n",
    "            except Exception as e:\n",
    "                print(f\"Error {orbit}: {e}\")\n",
    "        print(\"-\" * 160)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projection-head-geometry (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
